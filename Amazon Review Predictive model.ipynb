{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cf13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad3e6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 20, 2014</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>Exactly what I needed.</td>\n",
       "      <td>perfect replacements!!</td>\n",
       "      <td>1413763200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>09 28, 2014</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Sonja Lau</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>1411862400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>08 25, 2014</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>Love these... I am going to order another pack...</td>\n",
       "      <td>My New 'Friends' !!</td>\n",
       "      <td>1408924800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>08 24, 2014</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Jodi Stoner</td>\n",
       "      <td>too tiny an opening</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1408838400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>07 27, 2014</td>\n",
       "      <td>A89F3LQADZBS5</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>Alexander D.</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1406419200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  reviewerName  \\\n",
       "0        5      True  10 20, 2014  A1D4G1SNUZWQOT  7106116521         Tracy   \n",
       "1        2      True  09 28, 2014  A3DDWDH9PX2YX2  7106116521     Sonja Lau   \n",
       "2        4     False  08 25, 2014  A2MWC41EW7XL15  7106116521      Kathleen   \n",
       "3        2      True  08 24, 2014  A2UH2QQ275NV45  7106116521   Jodi Stoner   \n",
       "4        3     False  07 27, 2014   A89F3LQADZBS5  7106116521  Alexander D.   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0                             Exactly what I needed.   \n",
       "1  I agree with the other review, the opening is ...   \n",
       "2  Love these... I am going to order another pack...   \n",
       "3                                too tiny an opening   \n",
       "4                                               Okay   \n",
       "\n",
       "                                             summary  unixReviewTime  vote  \\\n",
       "0                             perfect replacements!!      1413763200   NaN   \n",
       "1  I agree with the other review, the opening is ...      1411862400   3.0   \n",
       "2                                My New 'Friends' !!      1408924800   NaN   \n",
       "3                                          Two Stars      1408838400   NaN   \n",
       "4                                        Three Stars      1406419200   NaN   \n",
       "\n",
       "  style image  \n",
       "0   NaN   NaN  \n",
       "1   NaN   NaN  \n",
       "2   NaN   NaN  \n",
       "3   NaN   NaN  \n",
       "4   NaN   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Main_Data = pd.read_json(\"/Users/farhanrashid/Downloads/Amazon Data file(Books)/AMAZON_FASHION.json\" , lines =True)\n",
    "\n",
    "\n",
    "Main_Data.head(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48c1ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define file paths\n",
    "file_paths = {\n",
    "    \"5_star\": \"/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_5_star.csv\",\n",
    "    \"4_star\": \"/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_4_star.csv\",\n",
    "    \"2_star\": \"/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_2_star.csv\",\n",
    "    \"1_star\": \"/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_1_star.csv\",\n",
    "    \"common_4_and_5\": \"/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_4_and_5_stars.csv\",\n",
    "    \"common_1_and_2\": \"/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_1_and_2_stars.csv\"\n",
    "}\n",
    "\n",
    "# Function to create and save smaller and testing datasets\n",
    "def create_datasets(file_path, smaller_file_path, testing_file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Create smaller dataset (first 20 rows)\n",
    "    smaller_df = df.head(20)\n",
    "    \n",
    "    # Create testing dataset (rest of the rows)\n",
    "    testing_df = df.iloc[20:]\n",
    "    \n",
    "    # Save the smaller and testing datasets\n",
    "    smaller_df.to_csv(smaller_file_path, index=False)\n",
    "    testing_df.to_csv(testing_file_path, index=False)\n",
    "\n",
    "# Generate the smaller and testing datasets for each file\n",
    "for key, file_path in file_paths.items():\n",
    "    smaller_file_path = file_path.replace(\".csv\", \"_smaller.csv\")\n",
    "    testing_file_path = file_path.replace(\".csv\", \"_testing.csv\")\n",
    "    \n",
    "    create_datasets(file_path, smaller_file_path, testing_file_path)\n",
    "\n",
    "print(\"Datasets created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85415372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load your datasets\n",
    "data_1_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_1_star_testing.csv')\n",
    "data_2_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_2_star_testing.csv')\n",
    "data_4_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_4_star_testing.csv')\n",
    "data_5_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_5_star_testing.csv')\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([data_1_star, data_2_star, data_4_star, data_5_star])\n",
    "\n",
    "\n",
    "data['reviewText'] = data['reviewText'].fillna('')\n",
    "\n",
    "# Assuming 'review' is the text column and 'rating' is the label column\n",
    "X = data['reviewText']\n",
    "y = data['overall']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2643378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_tfidf: (629220, 10000)\n",
      "Shape of X_test_tfidf: (157305, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_tfidf:\", X_train_tfidf.shape)\n",
    "print(\"Shape of X_test_tfidf:\", X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ceba715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.78      0.73     21321\n",
      "           2       0.46      0.26      0.34     12985\n",
      "           4       0.58      0.36      0.44     29774\n",
      "           5       0.81      0.93      0.87     93225\n",
      "\n",
      "    accuracy                           0.75    157305\n",
      "   macro avg       0.63      0.58      0.59    157305\n",
      "weighted avg       0.72      0.75      0.72    157305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "271c58e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_2.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'logistic_regression_model_2.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1e130bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Star Rating: 5\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('logistic_regression_model_2.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer_2.pkl')\n",
    "\n",
    "# Function to preprocess and predict the star rating for a new review\n",
    "def predict_star_rating(review_text, summary_text, vectorizer, model):\n",
    "    # Combine reviewText and summary\n",
    "    combined_text = review_text + ' ' + summary_text\n",
    "    \n",
    "    # Transform the combined text using the trained TF-IDF vectorizer\n",
    "    text_tfidf = vectorizer.transform([combined_text])\n",
    "    \n",
    "    # Predict the star rating using the trained model\n",
    "    predicted_rating = model.predict(text_tfidf)\n",
    "    \n",
    "    return predicted_rating[0]\n",
    "\n",
    "# Example new review and summary\n",
    "new_review_text = \"Love these... I am going to order another pack to keep in work; someone (including myself) is always losing the back to an earring.  I don't understand why all fish hook earrings don't have them.  Just wish that they were a tiny bit longer.  :)\"\n",
    "new_summary_text = \"My New 'Friends' !!\"\n",
    "\n",
    "# Preprocess and predict the star rating\n",
    "predicted_rating = predict_star_rating(new_review_text, new_summary_text, vectorizer, model)\n",
    "print(f\"Predicted Star Rating: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03d7d4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# gradient boastng\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load your datasets\n",
    "data_1_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_1_star_testing.csv')\n",
    "data_2_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_2_star_testing.csv')\n",
    "data_4_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_4_star_testing.csv')\n",
    "data_5_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_5_star_testing.csv')\n",
    "data_common_4_and_5 = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_4_and_5_stars_testing.csv')\n",
    "data_common_1_and_2 = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_1_and_2_stars_testing.csv')\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([data_1_star, data_2_star, data_4_star, data_5_star])\n",
    "\n",
    "# Fill NaN values in 'reviewText' with empty strings\n",
    "data['reviewText'] = data['reviewText'].fillna('')\n",
    "\n",
    "# Create user-level features (example: user review count)\n",
    "user_review_counts = data['userID'].value_counts().to_dict()\n",
    "data['user_review_count'] = data['userID'].map(user_review_counts)\n",
    "\n",
    "# Define feature set and labels\n",
    "X = data[['reviewText', 'user_review_count']]\n",
    "y = data['overall']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization for the text feature\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_text_tfidf = vectorizer.fit_transform(X_train['reviewText'])\n",
    "X_test_text_tfidf = vectorizer.transform(X_test['reviewText'])\n",
    "\n",
    "# Combine TF-IDF text features with user-level features\n",
    "import scipy\n",
    "X_train_combined = scipy.sparse.hstack((X_train_text_tfidf, X_train[['user_review_count']].values))\n",
    "X_test_combined = scipy.sparse.hstack((X_test_text_tfidf, X_test[['user_review_count']].values))\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_combined)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(model, 'gradient_boosting_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import scipy\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('gradient_boosting_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Function to preprocess and predict the star rating for a new review\n",
    "def predict_star_rating(review_text, user_review_count, vectorizer, model):\n",
    "    # Transform the review text using the trained TF-IDF vectorizer\n",
    "    text_tfidf = vectorizer.transform([review_text])\n",
    "    \n",
    "    # Combine TF-IDF text features with user-level features\n",
    "    user_features = scipy.sparse.csr_matrix([[user_review_count]])\n",
    "    combined_features = scipy.sparse.hstack((text_tfidf, user_features))\n",
    "    \n",
    "    # Predict the star rating using the trained model\n",
    "    predicted_rating = model.predict(combined_features)\n",
    "    \n",
    "    return predicted_rating[0]\n",
    "\n",
    "# Example new review\n",
    "new_review_text = \"This product is really amazing and exceeded my expectations.\"\n",
    "new_user_review_count = 10  # Example user feature\n",
    "\n",
    "# Preprocess and predict the star rating\n",
    "predicted_rating = predict_star_rating(new_review_text, new_user_review_count, vectorizer, model)\n",
    "print(f\"Predicted Star Rating: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7be8309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.57      0.61     21321\n",
      "           2       0.44      0.08      0.13     12985\n",
      "           4       0.54      0.29      0.37     29774\n",
      "           5       0.73      0.95      0.82     93225\n",
      "\n",
      "    accuracy                           0.70    157305\n",
      "   macro avg       0.59      0.47      0.49    157305\n",
      "weighted avg       0.66      0.70      0.65    157305\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import scipy\n",
    "\n",
    "# Load your datasets\n",
    "data_1_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_1_star_testing.csv')\n",
    "data_2_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_2_star_testing.csv')\n",
    "data_4_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_4_star_testing.csv')\n",
    "data_5_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_5_star_testing.csv')\n",
    "data_common_4_and_5 = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_4_and_5_stars.csv')\n",
    "data_common_1_and_2 = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_1_and_2_stars.csv')\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([data_1_star, data_2_star, data_4_star, data_5_star])\n",
    "\n",
    "# Fill NaN values in 'reviewText' with empty strings\n",
    "data['reviewText'] = data['reviewText'].fillna('')\n",
    "\n",
    "# Define feature set and labels\n",
    "X = data['reviewText']\n",
    "y = data['overall']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization for the text feature\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(model, 'gradient_boosting_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae8fc2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Star Rating: 5\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import scipy\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('gradient_boosting_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Function to preprocess and predict the star rating for a new review\n",
    "def predict_star_rating(review_text, vectorizer, model):\n",
    "    # Transform the review text using the trained TF-IDF vectorizer\n",
    "    text_tfidf = vectorizer.transform([review_text])\n",
    "    \n",
    "    # Predict the star rating using the trained model\n",
    "    predicted_rating = model.predict(text_tfidf)\n",
    "    \n",
    "    return predicted_rating[0]\n",
    "\n",
    "# Example new review\n",
    "new_review_text = \"Love these... I am going to order another pack to keep in work; someone (including myself) is always losing the back to an earring.  I don't understand why all fish hook earrings don't have them.  Just wish that they were a tiny bit longer.  :)\"\n",
    "\n",
    "# Preprocess and predict the star rating\n",
    "predicted_rating = predict_star_rating(new_review_text, vectorizer, model)\n",
    "print(f\"Predicted Star Rating: {predicted_rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22dcc03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/farhanrashid/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.57      0.61     21321\n",
      "           2       0.44      0.08      0.13     12985\n",
      "           4       0.54      0.29      0.37     29774\n",
      "           5       0.73      0.95      0.82     93225\n",
      "\n",
      "    accuracy                           0.70    157305\n",
      "   macro avg       0.59      0.47      0.49    157305\n",
      "weighted avg       0.66      0.70      0.65    157305\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import scipy\n",
    "\n",
    "# Load your datasets\n",
    "data_1_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_1_star_testing.csv')\n",
    "data_2_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_2_star_testing.csv')\n",
    "data_4_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_4_star_testing.csv')\n",
    "data_5_star = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/dataset_5_star_testing.csv')\n",
    "data_common_4_and_5 = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_4_and_5_stars.csv')\n",
    "data_common_1_and_2 = pd.read_csv('/Users/farhanrashid/Downloads/Amazon Data (BOOKS)/common_reviews_1_and_2_stars.csv')\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([data_1_star, data_2_star, data_4_star, data_5_star])\n",
    "\n",
    "# Fill NaN values in 'reviewText' with empty strings\n",
    "data['reviewText'] = data['reviewText'].fillna('')\n",
    "\n",
    "# Create user-level features (example: user review count)\n",
    "user_review_counts = data['reviewerID'].value_counts().to_dict()\n",
    "data['user_review_count'] = data['reviewerID'].map(user_review_counts)\n",
    "\n",
    "# Define feature set and labels\n",
    "X = data[['reviewText', 'user_review_count']]\n",
    "y = data['overall']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization for the text feature\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_text_tfidf = vectorizer.fit_transform(X_train['reviewText'])\n",
    "X_test_text_tfidf = vectorizer.transform(X_test['reviewText'])\n",
    "\n",
    "# Combine TF-IDF text features with user-level features\n",
    "X_train_combined = scipy.sparse.hstack((X_train_text_tfidf, X_train[['user_review_count']].values.reshape(-1, 1)))\n",
    "X_test_combined = scipy.sparse.hstack((X_test_text_tfidf, X_test[['user_review_count']].values.reshape(-1, 1)))\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_combined)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(model, 'gradient_boosting_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c38c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
